do_train: True
do_eval: True
model: 'BERT Pretrain'
gpu_num_per_node: 1
num_nodes: 1
node_ips: ['192.168.1.13', '192.168.1.14']
ctrl_port: 50051  #  ctrl_port for multinode job'
learning_rate: 1e-4
weight_decay_rate: 0.01
warmup_proportion: 0.1
use_fp16: False
use_xla: False
loss_print_every_n_iter: 10
model_save_every_n_iter: 10000
model_save_dir: ???
save_last_snapshot: False
model_load_dir: ???
log_dir: ./output
do_lower_case: True
seq_length: 512
max_predictions_per_seq: 80
num_hidden_layers: 12
num_attention_heads: 12
max_position_embeddings: 512
type_vocab_size: 2
vocab_size: 21128
attention_probs_dropout_prob: 0.1
hidden_dropout_prob: 0.1
hidden_size_per_head: 64